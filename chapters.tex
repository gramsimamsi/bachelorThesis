\chapter{Introduction}
With this chapter, the reader should be able to comprehend why this thesis was written, 
what it tries to accomplish and which topics are considered within the scope of this work.

\section{Motivation}

The increasing amount of Platform-as-a-Service (PaaS) solutions, cloud-hosted environments, containerized workloads and microservice architectures introduce new attack scenarios. 
Especially solutions providing Kubernetes (k8s) compliant container orchestration are identifiably different and in high demand compared to long established solutions. 
This creates the need for new defense strategies in both Development and Operations and calls for a more detailed, focused examination. 

\section{Objective} \label{goal}

The thesis aims to answer the following questions:

\begin{itemize}

\item What generic security risks emerge when providing or using a multi-tenant \gls{paas} solution,
with each tenant developing, deploying and running their own applications? 

\item What could a \gls{paas} provider (serving internal and/or external users) do to mitigate those risks? 

\item  In this scope and from a \gls{paas} provider viewpoint, how does an on-premise solution compare
to a public cloud solution? 

\end{itemize}

Another goal is to recommend security measures. \\
A comparison of existing risks and the need for action derived from it should serve as central point of view for implementing these measures as well as comparing the risks. 


After reading this thesis, the inclined reader should understand the underlying constructs of a solution within scope as well as the generic security risks present. When examining a specific solution, they should also be able to estimate values regarding the risk gravity to compare these risks among each other as well as compare them with those of other solutions. In addition to this, they have pointers to some of the security measures needed to reduce these risks and should be able to follow a suggested risk management process in order to adjust the solution to a desired security level.

\section{Scope limitation} \label{scopeLimit}

To achieve the aforementioned goals, the thesis will limit the view on the problem to a manageable scope by
concentrating on the components enabled by default and those required for operations of established and Kubernetes compliant solutions.

Since both the gravity of each risk and the comparison of on-premise and public cloud solutions would depend on a multitude of factors, specific solutions will be used as examples. These are \gls{ocp} and the \gls{aks} which respectively represent on-premise and public cloud solutions.
The vector risks will be assessed for these two exemplary solutions.
Carrying out a full risk management process for such solutions would exceed the scope of this thesis.
A demonstration by partially completing the risk management process aims to provide insight to the complete risk management process suggested.
Possible measures to reduce those risks shall be explored, evaluated and demonstrated in two practical examples.

The latest stable version of \gls{ocp} during the work on this thesis was version 3.11\footcite[][, see headline and date]{ocpRelease}, which is based on v1.11 of \gls{k8s}.
Although \gls{k8s} v1.13 was already available through \gls{aks} at the same point in time (see figure \ref{aksVersionsMay}), the available v1.11 was chosen to improve comparability.

The components of these two solutions providing \gls{k8s} compliance will be the main focus, as these bear the most relevance across all Kubernetes Certified solutions. 
A look at popular tools and frameworks used in such clusters will be avoided in order to keep the scope manageable, although some might be recommended as a mitigation.
In order to be applicable to a higher number of use cases, attacks and measures seen in environments with exceptionally high security requirements might be mentioned, but not  covered in their entirety. This includes state-sponsored actors deploying zero-day exploits, which are not applicable to a majority of solutions deployed and thus disregarded for the given context.
This thesis aims to provide insight to the risks of providing a \gls{paas} solution and mitigation thereof. 
As such, it will look at the capabilities a potential provider has to (mis-)configure such solutions - inherent risks of the technologies themselves are only explored when measures to mitigate them are accessible from a provider standpoint. 
In short, the goal is to improve the security of a given \gls{k8s} cluster, not \gls{k8s} itself.
To follow the \gls{owasp} Risk Rating Methodology\footcite{riskRating} down the line, threat actors have to be defined and grouped when applicable\footcite[][, Section 'Define all possible threats']{threatModeling}. Examining a list of threat actors published through SANS\footcite[][p. 12 to 17]{sansThreatActors}, only state-sponsored actors are excluded. This leaves us with cyber criminals, hacktivists, systems administrators, end users, executives and partners.
Grouping the remaining actors by the factors used to estimate risks in section \ref{riskEstimate}, three scenarios that encompass all of the actors can be identified:
%TODO Mention baseline security in summary!
%TODO change summary to fit the items here!
\begin{itemize}

\item Malicious third party attacking the solution from within the company network and/or the internet

\item Malicious third party attacking from inside a hijacked container, i.e. remotely executing code or commands

\item Bad user, i.e. a negligent, hijacked or malicious account risking compromise of their own and/or other applications

\end{itemize}

\section{Research basis and its limits}

During the research for this thesis, a considerable amount of sources has been examined. Surprisingly, very little has been found regarding a risk-based point of view on \gls{k8s} solutions. A lot of sources start with measures and end with attacks, including one of the few published books\footcite{k8sBook}. They recommend specific security measures and explain the sort or attacks they defend against. The only commonly referenced source that specifically introduces major risks for container technologies, without rating them, is the NIST Application Container Security Guide.\footcite{nistK8s}
In addition to that, many of them are still work in progress or outdated.

Some of the sources commonly referenced include (in alphabetical order):
\begin{itemize}

\item The \gls{cis} Docker Benchmark\footcite{cisDocker}

\item The \gls{cis} Kubernetes Benchmark\footcite{cisK8s}

\item The book "Kubernetes Security - How to Build and Operate Applications Securely in Kubernetes"\footcite{k8sBook}

\item The NIST Application Container Security Guide\footcite{nistK8s}

\item The \gls{owasp} \gls{csvs}\footcite{csvsGithub}

\item The \gls{owasp} Docker Top 10\footcite{dockerTop10Github}

\end{itemize}

Other sources include solution specific advisories, i.e. for \gls{k8s} in general\footcite{k8sDocsSecurity} as well as \gls{ocp}\footcite{ocpSecTips} and \gls{aks}\footcite{aksSecTips} specifically. In addition to that, recorded and openly available talks by different people in the industry are available. Especially the talks at KubeCon, the annual \gls{k8s} conference, are accessible through the \gls{cncf} YouTube presence\footnote{Channel Link: https://www.youtube.com/channel/UCvqbFHwN-nwalWPjPUKpvTA/videos}. The speakers include recognized people in the industry, contributors to the \gls{k8s} project and employees of reputable companies like Google, Red Hat and Microsoft.
A considerable number of other online sources were referenced in the sources above or found with online search engines.
These common recommendations exist, but neither claim to be exhaustive nor applicable to all future versions. In case of the \gls{cis} benchmarks, they are not even intended to be followed in full, but just as basis for security considerations\footcite[][, starting at 29:18]{cisJustRecommendation}.
In accordance to this, the findings can only be provided on a best-effort basis and not without reservation towards possible changes through future software versions or new information. This should be an information basis and approach for rating your own implementation while taking the business risk into consideration, not a definitive guide to all aspects in this regard.
As with all systems, new attacks and vulnerabilities may emerge at any point in time. With sufficient research, the chance to have identified the most common attack vectors is probable but the limitations of this research has to be emphasized.

\chapter{Theory}
With this chapter, the inclined reader with foundational knowledge of topics regarding Computer Science and/or Informatics 
will be able to grasp the specialized technologies discussed within the thesis and familiarize themselves with the definitions and terminology used throughout it.

\section{Platform-as-a-Service}

\begin{figure}[H]
\centering
\includegraphics[scale=0.4]{pictures/ServiceComparison.jpg}
\caption{Comparison of responsibilities in different service models\protect\footcite[][, section 'Original reference image']{servicecomparison}}
\label{fig:servicecomparison}
\end{figure}

In \gls{paas} environments, a consumer delegates the management and control of resources needed to deploy his applications to his \gls{paas} provider, beyond those covered by Infrastructure-as-a-Service\footcite[][p. 2 to 3]{nistcloud}.
In an ideal scenario, this leads to a consumer not having to concern himself with the underlying network, hardware, servers, operating systems, storage or even common middleware like database management or log collection and analysis\footcite[][, section 'Advantages of PaaS']{msPaas} and allows them to focus on other tasks, i.e. application development.
As a downside to this, a consumer might only have limited control on, among other factors, the software installed on the provisioned machines. 
Although this shifts some of the responsibility burden towards the provider, the situation isn't as clear-cut as one might think. 
Figure ~\ref{fig:servicecomparison} shows middleware and runtime as provided, but there is no clear standard on what capabilities or tools are included.
A consumer might require capabilities which aren't provided or wishes to avoid provider lock-in through proprietary tools, 
resulting in some middleware responsibilities falling back to the consumer. 
A consumer might also have to extensively configure or modify the application-hosting environment for compliance or security purposes. 
Even some low-level tasks aren't completely managed, i.e. VM reboots to apply security updates\footcite[][, section 'Process Linux node updates and reboots using kured']{msVmReboot}.

\section{Containers}

Unsurprisingly, a basic building block of running containerized applications are containers.
In order to run and manage containers, several components and systems are needed. The most important ones will be introduced here.

\subsection{What are containers?}
A container is a standard unit of software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another\footcite[][, section 'Package Software into Standardized Units for Development, Shipment and Deployment']{whatContainer}.
From a technical viewpoint, a container is an isolated process running in the userspace of a host OS. The host system shares the kernel with all containers on it and might share other resources, but containers are run from container images which include any code and dependencies needed in order to make them independent of the infrastructure they are running on (except the kernel)\footcite[][, slide 13]{containerIntro}.

Linux containers were widely popularized through Docker, a container system initially based on a technology called LinuX Containers\footcite[][, section '2013: Docker']{containerHistory}.
Containers provide isolation of multiple applications running on the same machine and are often deployed in environments where this isolation would formerly have been achieved by using multiple VMs. Thus, they are often compared to them despite the fundamental technical differences. The Kubernetes documentation illustrates the differences as seen in Figure ~\ref{fig:VMsVsContainers}.

\begin{figure}[H]
\centering
\includegraphics[scale=0.3]{pictures/VMsVsContainers.jpg}
\caption{Comparison of different application deployments on the same hardware\protect\footcite[][, section 'Going back in time']{k8sBasics}}
\label{fig:VMsVsContainers}
\end{figure}

\subsection{Differentiating docker}
Talking about docker can be quite difficult, since the term is overloaded with different meanings - a company (Docker Inc.), their commercial products (Docker CE and Docker EE) and the former name of their open source project (formerly known as Docker, now called Moby)\footcite[][, section 'What is Moby?']{dockerMoby}.
Additionally, there is a \gls{cli} called docker engine, which serves as an interface to the containers running on a host. It includes a high-level container runtime\footcite[][, section 'Develop, Ship and Run Any Application, Anywhere']{dockerEngine}, which will be talked about in the section \ref{runtimes}.
Some sources also talk about docker-formatted containers when those technologies implement the same interfaces as the docker container runtime\footcite[][, section '1.11. Working with Docker formatted containers']{dockerFormatted}, which will be adopted in this thesis.

\subsection{Images, image building and Dockerfiles}
A container image is a binary including all the data needed to run a container. It might also contain metadata on its needs and capabilities, i.e. version information through tags\footcite[][, section 'Docker Images']{redhatImages}.
Container images are sometimes referred to as docker images or docker-formatted images, but they can be run by other container runtimes and vice versa.
In order to create a container image, you have to build it. This is often done through a build process executed by a container runtime. The instructions for container builds are commonly defined and documented in a Dockerfile\footcite[][, section 'Dockerfile reference']{dockerfileDocs} (which may also be done by non-docker programs, adding to the vocabulary confusion).
Container images can be distributed through container image registries, where images can be uploaded to and downloaded from. A commonly known example is docker hub, a public registry run by Docker Inc.

\subsection{Container standards and interfaces} \label{runtimes}

Without going into the nuances and historical developments, there are a multitude of programs mostly implementing three interfaces for container management.
The two basic interfaces are the runtime and image specifications under the \gls{oci} which standardize how containers and container images should be formatted and executed\footcite[][, first paragraph]{ociStandards}.
The \gls{oci} also maintains a commonly used reference implementation called runc, alternatives include rkt and lmctfy\footcite[][, section 'Examples of Low-Level Container Runtimes']{lowLevelRuntimes}.
Runc and similar programs implementing these specifications are commonly called low level runtimes, in contrast to the high level runtimes that control them.
These high level runtimes like containerd or CRI-O commonly manage more abstract features like downloading and verifying container images\footcite[][, Intro and section 'Examples of High-Level Runtimes']{highLevelRuntimes}.
Many high level runtimes today adhere to the \gls{cri} so they can be used interchangeably by container orchestrators\footcite[][, section 'Purpose']{criGithub}.

\section{Container orchestration}
Once you want to use multiple containers on different machines talking to each other and offering stable services that continue even when one container or machine fails, the need for automated systems to manage these containers arises. Orchestrators can also provide other advantages like load balancing and automated scaling.
Kubernetes systems are popular orchestrators currently in use.
The sum of hosts running the orchestrator and containers are called a cluster.

\subsection{Kubernetes} \label{k8sTheory}
At its core, \gls{k8s} is a control system for containers.
It constantly compares the current state with the set target state and tries to correct towards the target when needed, i.e. when a container crashes.
The intended way for a user to deploy or change their application is to adjust the target state and let the \gls{k8s} system take care of the rest\footcite[][, section 'Understanding Kubernetes Objects']{k8sObjects}.
There are many \gls{k8s} distributions, many of which are certified Kubernetes offerings, meaning they all comply to the same standards and interfaces. These are set by the Linux Foundation through the \gls{cncf} which oversees the project.
The Kubernetes code base is open source and maintained on GitHub, but any implementation fulfilling the (publicized) requirements can become \gls{k8s} certified, regardless of how much code they changed\footcite[][, section 'There are over 80 Certified Kubernetes offerings.']{certifiedK8s}.
You could look at \gls{k8s} as a standardized interface for container orchestration with a public reference implementation.

\subsubsection{Kubernetes components} \label{k8sComponents}

In order to deliver a working \gls{k8s} cluster, multiple (binary) components are needed.
Master components provide the control plane, while node components are run on each underlying machine in order to maintain and provide the environment to execute the containers you want to run eventually.
Master components are often exclusively run on machines dedicated to them, which are called master nodes - in contrast to worker nodes, which run the containers your applications consist of\footcite[][, section 'Master Components']{k8sComponents}.

The most relevant master components from the perspective of this thesis are:
\begin{itemize}

\item The kube-apiserver, which exposes the Kubernetes API. It is the front-end for the Kubernetes control plane; Cluster user or Administrator commands are typically directed at and processed by this component.

\item Etcd, a distributed high-availability key value store where, among other things, secrets and authentication information are stored.

\end{itemize}

The important node components include:
\begin{itemize}

\item The kubelet, an agent running on each node in the cluster. It mostly monitors the state of any containers started by the \gls{k8s} cluster. These are run through pods, a Kubernetes object designated to executing containers. The kubelet also interacts with the master components and reports on the monitoring data.

\item The container runtime as depicted in figure \ref{fig:VMsVsContainers}, which is responsible for actually running containers. Examples include \gls{ocp} using Docker while \gls{aks} uses Moby, but any implementation of the \gls{cri} is supported.\footnote{For additional information, refer to section \ref{runtimes}} 

\end{itemize}

Figure \ref{fig:k8s-big-picture} illustrates these components in context. It is to note that users in this illustration are the users of the applications running in the cluster. From a platform provider standpoint the users would be the people responsible for development and operations.

\begin{figure}
\centering
\includegraphics[scale=0.2]{pictures/big-picture.JPG}
\caption{An overview of different \gls{k8s} components\protect\footcite{nicoPictures}}
\label{fig:k8s-big-picture}
\end{figure}

%TODO component functions and number may vary per distribution

\subsubsection{Kubernetes objects}
Kubernetes objects are persistent entities that represent the desired state of your cluster. They can describe what containers should run, which resources are available to what system and the policies to apply (i.e. automatic restart behavior and communication restrictions).
The intent is to modify these objects in order to change the target state, which the \gls{k8s} system then works towards by adjusting the current state to match\footcite[][, section 'Understanding Kubernetes Objects']{k8sObjects}.
Some objects, i.e. pods, belong to a specific namespace, meaning a virtual cluster of many in a shared physical cluster. Others, like node objects describing the underlying machine, exist outside of a specific namespace.
In order to understand how one can make the \gls{k8s} system run an application according to its requirements, an understanding of the basic objects is needed. \\
%TODO make object names bold/italics? also do that to all other important names/definitions in the theory chapter?
A pod is the basic \gls{k8s} object and encapsulates a container with some resources like an IP, storage and policies. Pods are typically each comprised of one container, a single instance of an application in \gls{k8s}. They may contain more than one container for cases where these are tightly coupled and directly share resources\footcite[][, section 'Understanding Pods']{k8sPods}.
That's all the pods do. They run\footcite[][p. 4]{phippy}. \\
Pods are usually not created manually, but started and stopped by a replicaSet. Their purpos as a \gls{k8s} controller is to maintain a stable set of replica pods running at any time in order to ensure availability of the function this type of pod provides\footcite[][, introductory sentence]{k8sReplicaSets}.
ReplicaSets are in turn managed by deployments. Just as replicaSets control pods, deployments control replicaSets in order to maintain the currently desired state of a cluster.
Figure \ref{fig:k8s-deployments} illustrates this connection. \\

\begin{figure}[H]
\centering
\includegraphics[scale=0.2]{pictures/deployment.JPG}
\caption{Connection between deployments and other \gls{k8s} objects down to containers\protect\footcite{nicoPictures}}
\label{fig:k8s-deployments}
\end{figure}

\newpage
Since multiple identical pods may provide the same functionality and instances of this type of pod could be stopped or started at any point, how could a pod or other system address and connect to a pod? This can be solved by configuring a service, which abstracts a set of pods and their access policy. Typically, you talk to services instead of other pods directly. These services might then be published cluster-externally, i.e. through a load balancer provided by a cloud provider as seen in figure \ref{fig:loadbalancer}.

\begin{figure}
\centering
\includegraphics[scale=0.2]{pictures/loadbalancer.JPG}
\caption{Connection between deployments and other \gls{k8s} objects down to containers\protect\footcite{nicoPictures}}
\label{fig:loadbalancer}
\end{figure}

%TODO other objects: volumes, daemonsets, podsecuritypolicies, networkpolicies, (others needed/referenced?)

\subsubsection{Using Kubernetes}
There are many ways and solutions to set up a \gls{k8s} cluster. Anyone can write their own one from scratch, but so-called turnkey solutions for cloud and on-premise environments exist, too, which significantly reduce the time and effort required to set up and run a cluster\footcite[][, sections 'Turnkey Cloud Solutions' and 'On-Premises turnkey cloud solutions']{turnkey}.
%TODO maybe: buy CaaS/PaaS/IaaS, cloud vs. on-prem, different scopes/features from different products
Once your cluster is set up, it is typically interacted with through the \gls{k8s} API. For human interaction, kubectl is a \gls{cli} reference implementation which enables remote interaction with it\footcite[][, section 'The Kubernetes API']{k8sApi}.
In order to create or manipulate an object, you need to provide its new specification. This is typically supplied to kubectl as a .yaml file, an example of which can be seen in listing \ref{lst:example-yaml-file}\footcite[][, section 'Describing a Kubernetes Object']{k8sObjects}.

\begin{lstlisting}[
	caption={Exemplary .yaml file of a simple \gls{k8s} deployment},
	basicstyle=\tiny,
	label={lst:example-yaml-file}]
apiVersion: apps/v1 # for versions before 1.9.0 use apps/v1beta2
kind: Deployment
metadata:
  name: nginx-deployment
spec:
  selector:
    matchLabels:
      app: nginx
  replicas: 2 # tells deployment to run 2 pods matching the template
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
        ports:
        - containerPort: 80
\end{lstlisting}

%TODO custom yaml highlighting? https://tex.stackexchange.com/questions/152829/how-can-i-highlight-yaml-code-in-a-pretty-way-with-listings/152856#152856

\subsection{OpenShift} \label{openshiftExplanation}

OpenShift is a commercial Kubernetes container platform by Red Hat of which there are several different options to choose from. OpenShift Online is hosted in a public cloud, while OpenShift Dedicated is hosted on dedicated nodes in a virtual private cloud. The option used in this thesis is \gls{ocp}, which can be deployed on any infrastructure, including on-premise environments\footcite[][, section 'OpenShift plans and pricing']{openShiftOptions}.
Red Hat sponsors and supports the development of Fedora, a Linux distribution on which they base their \gls{rhel} OS on. \gls{rhel} is then used by them commercially by supplying its binaries and updates through commercial licenses.
Similar to this, Red Hat develops and supports a \gls{k8s} distribution called \gls{okd}, which then serves as a base for all versions of OpenShift products\footcite[][, section 'OKD vs Red Hat OpenShift']{ocpVsOkd}.
\newpage
\gls{okd} release versions correspond to the \gls{k8s} version it is based on, i.e. \gls{okd} 1.11 is based on \gls{k8s} 1.11\footcite[][, section 'What is OKD?']{okd}.
\gls{ocp} versions may differ, but Red Hat maintains a list of tested integrations for each major \gls{ocp} release, giving insight to which \gls{k8s} version it is based on\footcite[][, table 'Platform Components']{ocpK8sVersions}.
\gls{ocp} is a certified Kubernetes distribution, which means it implements the same interfaces as all the others\footcite[][, table 'Platform - Certified Kubernetes - Distribution']{certifiedK8s}.
Despite this, the differences in intended usage become apparent quite quickly, starting with the \gls{cli} used to interact with a cluster (oc instead of kubectl).
Even basic concepts like namespaces are different, as \gls{ocp} uses the similar but not identical concept of projects\footcite[][, section 'Overview']{ocpProjects}.
Another difference of note is is the mechanic of \gls{scc}, which are the OpenShift equivalent of and initial inspiration for \gls{k8s} Pod Security Policies.
\gls{ocp} uses Docker as its default container runtime.

\subsection{Azure Kubernetes Service}

The Azure Kubernetes Service is a managed \gls{k8s} solution offered by Microsoft and running in the Azure public cloud. 
As it does not differ from the \gls{k8s} reference implementation compared to \gls{ocp}, its functionality is identical to the general \gls{k8s} mechanics described in section \ref{k8sTheory}.
The computing resources used to run the cluster are pre-configured and provisioned VMs in the Azure cloud, which do not need to be configured and run a container runtime based on Moby, a toolkit from which the Docker runtime is built\footcite[][, section 'What is Moby?']{dockerMoby}.
\gls{k8s} versions in \gls{aks} directly correspond to the \gls{k8s} version they are based on.
As many cloud services do, there are multiple integrations to other cloud services, in case of \gls{aks} including an option to integrate your Azure Active Directory to authenticate users\footcite[][, first paragraph]{aadAksAuth}.

%TODO any context missing here?

\chapter{Deriving the attack surface and security measures} \label{deriveRisks}
\setcounter{footnote}{0}
%derive all vectors from the three scenarios, explain why you cannot prove that this is/will be everything, explain why grouped this way \& which systems/threat actors rolled together in it. List security measures for each.
%TODO review when done - missed anything of ^this?

Picking up the three scenarios of section \ref{scopeLimit}, the possible attack vectors are  identified in this chapter to get an overview of the attack surface posed by \gls{k8s} systems. Vectors and the possible attacks by different threat actors are explained as well as potential security measures introduced.

\section{Defining procedure and approach}

The identification of attack vectors within scope turned out to be a big challenge, both in research and preparation for a clear presentation. 
As new minor versions of \gls{k8s} are released approximately every tree months and the Kubernetes project only maintains release branches for the most recent three minor releases\footcite[][, section 'Supported versions']{k8sSupport}, the underlying system evolves continuously. Due to lengthy review processes, accredited literature about the topic is rare and risks being outdated quite quickly. Even less formal sources like blog posts or guidelines published by organizations are both rare, still unfinished at the point of this writing or updated continually, further complicating the creation of a snapshot regarding the current state. Nonetheless, it was attempted to achieve it on a best-effort basis.
These vectors are applicable to all \gls{k8s} solutions, although the available security measures will vary between different products or implementations. Thus, applicable  generic measures will be mentioned and specific \gls{aks} and \gls{ocp} examples may be provided for further illustration.
%TODO ^leave 'specific examples in? did you provide any?
In order to give a more comprehensible picture, the scope of these vectors varies. Some areas of interest, i.e. unpatched software and vulnerabilities in the underlying server  infrastructure, have a broad scope. Since they are well known security topics applicable almost all information technology, they have been broadly encapsulated for a more clear understanding. If there would be rigorous differentiation between only slightly different vectors, this list would be multiple times as long as it already is.

%TODO say that this is not perfect, but more would be out of scope / no time left?
%TODO more on how the vectors were grouped!

\section{Identified vectors and security measures} \label{vectorIdentify}
The following headlines will each respectively define and explain one of the 17 identified attack vectors of this thesis. For brevity of reference, each has a Vector ID assigned which is formatted as V\textit{xx}.

%TODO mention these generic measures?
%LOG ALL THE THINGS
%	ELK/EFK-stack or Splunk with log forwarding/aggregation (container AND nodes), k8s audit logging (k8s)
	
%MONITORING AND ALERTING
%	prometheus, grafana (visualization), neuvector, (sysdig) falco, aqua, twistlock


\subsection{V01 - Reconnaissance through interface components} \label{v01}
An attacker could gather information through the available interfaces in order to prepare further attacks and look for vulnerabilities to exploit.
A \gls{k8s} cluster has many interfaces, some of which are intended to be accessed by users or other non-master-components. These components include the kube-apiserver introduced in section \ref{k8sComponents}, the popular web-based \gls{k8s} user interface called Dashboard\footcite[][, first paragraph]{k8sDashboard} as well as solution-specific interfaces like the \gls{ocp} web console\footcite[][, section 'Overview']{ocpWebConsole} or the Azure Portal for \gls{aks}\footcite[][, section 'Create an AKS cluster']{azurePortal}.
Other interfaces are intended to be accessible from inside a cluster. These may include the components accessible from cluster-external sources, but also APIs for the integration of additional functionality. A common use case for such APIs is the provisioning of additional cloud resources in order to scale up the cluster.
One example of reconnaissance against the kube-apiserver was demonstrated at KubeCon 2019\footcite[][, starting at 8:45]{lizReconDemo}, while an example of leveraging the cloud api can be found in a blog post\footcite{aksApiExploit}. \\
Following the security principle of limiting the attack surface\footcite[][, p. 4 to 5]{k8sBook}, the measures against this include blocking access to or outright deactivating interfaces. If interfaces are unused, i.e. the \gls{k8s} Dashboard where only \gls{cli} tools are used for cluster interaction, one can easily deactivate the Dashboard and thus reduce the attack surface without further work needed. If an interface is used, but alternatives exist, it may be advisable to evaluate whether a change in workflows or software architectures in order to decommission the interface may provide an overall benefit.
Least privilege, another security principle\footcite[][, p. 3 to 4]{k8sBook}, can be followed by restricting access to used interfaces. Authentication can be required of both humans and automated processes and their access may be restricted to the information and capabilities strictly needed to operate. KubiScan, an open source tool to scan the role-based access control permissions of a \gls{k8s} cluster for permissions considered risky, is publicly available to assess a given cluster. Users might be required to log in through a two factor authentication to hinder access through stolen credentials. Network restrictions can be put in place to restrict the vantage points from which an attacker may gain access.
Following Defense in Depth\footcite[][, p. 3]{k8sBook}, this should not only be done from the outside, but access from inside the cluster, too. As an example, most containers don't need access to \gls{k8s} master components, so these requests can be blocked by \gls{k8s} Egress Network Policies\footcite[][, section 'The NetworkPolicy Resource']{egressNetPol}. The impact of successful attacks could be limited through alerting and restricting of the attacks 'blast radius'. Logging and alerting processes may be implemented through \gls{k8s} audit policies\footcite[][, section 'Audit Policy']{auditPolicy} for requests that are considered suspicious and do not occur in normal operations, examples of which can be found in online sources\footcite[][, section 'Alerting on the Kubernetes infrastructure']{sysdigMonitoring}. The 'blast radius' may be reduced by isolating different applications or teams trough multiple namespaces and restricting access to non-namespaced resources to cluster administrators, thus isolating an attacker to a single namespace instead of the whole cluster. An even more drastic isolation could be achieved through isolation by cluster, resulting in separate \gls{k8s} master components per isolated entity.

\subsection{V02 - Reading confidential information through interface components}
The components mentioned in section \ref{v01} could also be used by an attacker to gather confidential information, which can be either useful in and of itself or used to gain further access. Extracted private keys, tokens or passwords  may be leveraged to gain privileges in order to manipulate container images, adjacent applications, source code and interact with other interfaces. \\
Despite presenting a more serious damage potential, the measures of section \ref{v01} also apply here since they target the same interfaces.
In addition to that, special attention should be paid to the way secrets are passed into code running under \gls{k8s}. Embedding secret information into container images should be avoided, since those are not only unencrypted and difficult to change, but may be extracted by an attacker reading the Dockerfile or inspecting an image themselves. Supplying them through environment variables is also not recommended, as those might be exposed in unconsidered ways. It is recommended to supply them to containers at runtime through \gls{k8s} secrets or external tools like those integrated into cloud platforms or offered by third-party providers. Popular third-party solutions include HashiCorp Vault and CyberArk Conjur\footcite[][, chapter 7]{k8sBook}.

\subsection{V03 - Configuration manipulation through interface components} \label{v03}
With write access to the components mentioned in section \ref{v01}, an attacker may change the cluster or environment configuration, i.e. security controls set in place through the cloud provider platform. Examples include disabling security restrictions, rendering alerting processes dysfunctional by blocking their communication or swapping container images with functional, but compromised alternatives. 
\newpage
As this has a higher potential for damage, special care should be taken. The measures of section \ref{v01} are applicable here, too. Special thought may be put into restricting write permissions to the most privileged user accounts, i.e. cluster or cloud administrators for actions that can influence systems outside of a namespace or cluster.
In order to automatically deny actions, \gls{k8s} Pod Security Policies\footcite[][, section 'What is a Pod Security Policy?']{securityPolicy} may be leveraged. Since these are non-namespaced \gls{k8s} objects themselves, they could be circumvented by anyone with permissions to manipulate non-namespaced objects, i.e. cluster administrators.

\subsection{V04 - Compromise internal master components}
In contrast to the components mentioned in section \ref{v01}, there are others which are only intended to be interacted with by other \gls{k8s} master components. They may also be compromised by an attacker and are furthermore referred to as internal components.
The most promising target is the etcd key value store introduced in section \ref{k8sComponents}, as through it an attacker may gain any permission they want\footcite[][, chapter 'Running etcd Safely']{k8sBook}. \\
The available security measures are much more straightforward than those of the interface components, which is why all (ab)use cases have been united in one vector.
Master components can be run on any machine in the cluster, but are often run on dedicated master nodes\footcite[][, section 'Master Components']{k8sComponents}.
Therefore, \gls{k8s} solutions can restrict access to these by either not exposing them to anyone outside the pool of master nodes or, in case the components themselves are deployed as containers, restricting write access to their namespace they are running in as well as communication to the containers themselves.
Synonymous to section \ref{v01}, isolating through separate clusters per team or application can restrict the damage potential through separate master components.

\subsection{V05 - Image poisoning and baiting} \label{v05}
An attacker may try and lead a cluster user to run containers from a container image that is either controlled by the attacker or insecure\footcite[][, p. 13 to 14]{nistK8s}.
This could be done as an untargeted attack by offering images on popular public image repositories like Docker Hub or providing examples of similarly bad Dockerfiles in tutorials or support forums.
Since building new containers from scratch is a lot of work, container images for popular applications are often sought to either build upon or use out-of-the-box.
Applications for which no official container image is maintained are an especially common niche for such attacks.
In contrast to this, an attacker could also try a more targeted attack by uploading bad images to the (possibly private) repository used by their target.
Even previously trusted images may become insecure over time as new vulnerabilities are publicized, thus becoming "stale"\footcite[][, p. 14]{nistK8s}.
It should be noted that providing Dockerfiles instead of images may be easier to identify as malicious, but when a user builds an image from it anyway, the build process will commonly run under a root user\footnote{While \gls{k8s} currently doesn't provide image building capabilities out-of-the-box, many \gls{k8s} certified solutions implement this functionality.}. \\
In order to mitigate all of the above, only safe images should be used to run containers within a cluster. Although this sounds simple in theory, it may prove to be far more complex in practice. One would first have to define what constitutes a safe image in their context before implementing any measures ensuring their usage.
Docker Hub introduced measures that help identifying more trustworthy images by labeling them as Verified Publisher Images or Certified Images respectively\footcite[][, sections 'Verified Publisher Images and Plugins' and 'Certified Images and Plugins']{safeImagesDockerhub}.
In order to restrict the amount of possible images used, a private registry could be used and the cluster restricted to only using images from that registry. User may then be allowed to build new images based on those in the registry and upload those to it. 
The damage potential of images may be limited by restricting the capabilities a container may gain through the Pod Security Policies introduced in section \ref{v03}.
Images could also go through a (either manual or automated) vetting process before being admitted to a registry. Images in a registry may be reassessed on a regular basis, too, so images with known vulnerabilities can be identified and removed. Multiple tools that provide automated image scans exist and can be found online\footcite[][, section 'Securing your container images']{k8sBookWebsite}, some of which provide integration into \gls{k8s} clusters or cloud platforms.

\subsection{V06 - Configuration poisoning and baiting}
An attacker may try and lead a cluster user or even administrator to configure the cluster in such a way that the attacker gains control, the cluster is left insecure, or both\footcite[][, p. 13 to 14]{nistK8s}.
This vector has a lot in common with the one described in section \ref{v05}. A bad configuration might include bad containers, but does not have to, which is why we kept this as a separate vector. Attacks like this are far easier to do untargeted by offering tutorials and posts in support forums, but might also be conducted in a targeted way, similar to spear phishing attacks.
The number of possibilities for specific bad configurations is near endless. Easy and effective misconfigurations may be achieved by swapping out popular image names with similar ones controlled by the attacker (i.e. 'nodejs' instead of 'node'), preconfiguring weak or attacker known default passwords, simply omitting or misconfiguring security measures so they do not work effectively (i.e. defining Network Policies, but not applying them) or making internal interfaces available to the public network. \\
\newpage
As there are many potential ways for misconfiguration, there are also many measures to mitigate them.
Raising user and administrator awareness for the risk of using a configuration supplied by outsiders is recommended. Continuously training them to provide the knowledge needed to thoroughly understand and assess these configurations may help in mitigating this problem, too. 
Free and helpful tools in assessing configurations are kubesec.io, kube-bench\footnote{https://github.com/aquasecurity/kube-bench} and kubeaudit\footnote{https://github.com/Shopify/kubeaudit}.
Defining guidelines and best practices for configurations could be done and enforced by regular manual reviews or automated checks through tools like the Open Policy Agent admission controls\footcite[][, section 'Wrap Up']{opaAdmission} or k8Guard\footnote{https://k8guard.github.io/}.
As bad configurations may include bad containers, the measures introduced in section \ref{v05} are applicable, too.

\subsection{V07 - Lateral movement through cluster} \label{v07}
Once an attacker gains access to a container, he may try to access more lucrative information, applications or cluster components. Ways to achieve this could be sniffing network traffic or scanning the network for other containers, hosts, services, apis or similar interfaces. \\
Applicable security measures include network isolation through Network Policies\footcite[][, section 'The NetworkPolicy Resource']{netPols} and mutual TLS authentication for network communication through tools like Istio\footcite[][, section 'Mutual TLS authentication']{istioMtls}.

\subsection{V08 - Container breakout} \label{v08}
A popular phrase about container security is that "[c]ontainers do not contain"\footcite[][, first headline]{doNotContain}.
Once an attacker is able to execute commands in a container within the cluster, he may try influence components outside its isolation confinements. 
If an attacker successfully gains access to the underlying system, they might gain visibility into or control over any container running on it, including those of other applications. Additionally, they could gain access to internal cluster components like the kubelet.
Ways to achieve this include the invocation of syscalls, accessing mounted parts of the host file system and requesting additional capabilities. More ways to achieve this  have been demonstrated\footcite[][, section 'Breaking down the proof of concept']{trailOfBitsEscape} and are being discussed at the time of this writing as the \gls{owasp} Docker Top 10 are worked on\footcite[][, dialogue by GitHub users 'drwetter', 'gramsimamsi' and 'wurstbrot']{dockerTop10GithubIssue}. \\
\newpage
This can again be reduced by restricting the capabilities and host access a given container is provided through the Pod Security Policies mentioned in section \ref{v03}.
"Sandboxed" containers may be leveraged here, too, which provide more isolation between a container and its host at the cost of performance. Popular implementations include gVisor\footnote{https://github.com/google/gvisor} and Kata Containers\footnote{https://katacontainers.io/}.

\subsection{V09 - Image cache compromise}
If the container image cached by a container runtime on the underlying host system is swapped out by an attacker, another container controlled by the attacker might be started. \\
In order to mitigate this, container runtimes may support capabilities to check for the integrity of a container image. An example of such features is Docker Content Trust, which enables integrity verification at runtime\footcite[][, section 'About Docker Content Trust (DCT)']{dockerContentTrust}.

\subsection{V10 - Container modification at runtime} \label{v10}
Instead of starting bad containers as discussed in section \ref{v13}, an attacker may try to modify it in order to suit their needs and support further attacks.
This may be done by downloading and running additional binaries, establishing connections to Command and Control Servers or manipulating the software and files in place. \\
Measures against this build include limiting the capabilities a container has as discussed in section \ref{v03}. Limiting network connections to cluster-external sources may mitigate ways to download additional software or exfiltrate data. This could be done via Egress Network Policies, which section \ref{v01} introduced.
Monitoring tools could be used to detect this, of which several commercial products are offered and often integrated into (cloud) provider platforms\footcite[][, slide 40 to 41]{runtimeProt}.

\subsection{V11 - Resource hoarding (sabotage)} \label{v11}
An attacker with the ability to use resources or manipulate configuration may misuse or misconfigure them in order to disrupt the availability of specific applications or the cluster as a whole in DOS attacks.
This may be done in a myriad of ways. Exhausting the available resources through fork bombs\footcite[][, chapter 'Fork Bombs and Resource-Based Attacks']{k8sBook} or intensive use of memory, RAM, network bandwidth, processing power or available network ports may be a straightforward technique. They could also delete data and binaries, i.e. \gls{k8s} objects and node programs and operating system components, wherever they have access to.
If an attacker tries to achieve disruption for a long period of time, they could misconfigure the setup in a way that is either difficult to debug or reverse. \\
Measures against this include dedicated master nodes, which are a common practice anyway, in order to keep entities without administrator access from affecting the master nodes an master components running on them. Synonymous to section \ref{v01}, isolating applications or teams through different namespaces or even clusters would reduce the 'blast radius' of a successful attack. Once this isolation is in place, resource quotas\footcite[][, section 'Viewing and Setting Quotas']{resourceQuota} could be set in place to constrain the total resource consumption of a namespace. Tools to monitor usage\footcite[][, first paragraph]{k8sResourceMonitoring} could be set in place, as well as alerting mechanisms for unusually high resource consumption. Misconfiguration could be mitigated by the same logging and alerting measures introduced in section \ref{v01}. Deployment management tools like Helm could also be used, which simplify persisting the \gls{k8s} object states in a version-control system.

\subsection{V12 - Resource misuse (cryptojacking)}
Instead of sabotaging the cluster and/or applications, an attacker may use resources they can allocate to achieve monetary gain. This is often done by mining cryptocurrencies. The most commonly cited example for this is the incident of electric car manufacturer Tesla, where attackers used the control gained over their cloud infrastructure to run mining software in order to gain cryptocurrency with resources paid for by the company\footcite[][, section 'The Latest Victim: Tesla']{teslaIncident}. \\
The measures against this include those introduced in section \ref{v11}. As this vector might be more difficult to detect if done well, a focus on detection may be of use.
More advanced measures are presented by RedLock, the company which uncovered the Tesla incident, on their blog\footcite[][, section 'Preventing Such Compromises']{teslaIncident}.

\subsection{V13 - Adding rogue containers} \label{v13}
\vspace{-0.25cm}
In contrast to sections \ref{v05} and \ref{v10}, an attacker or malicious user capable of starting containers in the cluster may simply start their own malicious one. Since they could try to configure it in any way they want, this could help them in further attacks, leveraging vectors like those described in sections \ref{v07} or \ref{v08}. \\
The mitigations of section \ref{v10} mostly apply here, except for those against downloading additional binaries at runtime. An attacker could simply supply these within a Dockerfile or container image so they would already be installed. Against this, the detection and mitigation measures against bad images described in section \ref{v05} are applicable.

\vspace{-0.25cm}
\subsection{V14 - Adding rogue nodes}
\vspace{-0.25cm}
An attacker could try and add a host as a cluster node which is controlled by them. If successful, containers will be scheduled on the new node, allowing an attacker access to these containers in order to read, exfiltrate or manipulate data. They would also have control over the kubelet on this node, as described in section \ref{v08}.
In a sufficient time period, the chance of any container in the cluster running on the node at least once increases. This process could be sped up by manipulating the reporting data sent by the kubelet to the kube-scheduler, faking a lot of unused resources on it so more containers are scheduled. \\
In order to mitigate this, nodes would have to authenticate themselves to the apiserver and permissions to add new nodes should be limited to the highest possible user accounts like cluster administrators.

\vspace{-0.25cm}
\subsection{V15 - Leveraging bad user practice}
\vspace{-0.25cm}
An attacker may leverage bad user practice to gain access to or permissions within a cluster. 
This vector comprises user practices outside of the cluster that lead to risks within it.
Examples include phishing for user accounts, gathering keys/tokens published to public code repositories, gathering passwords published in credential leaks or dumps, scouting specific software or container images used as well as gathering logs published with information valuable to an attacker.
This could be done in a targeted way (i.e. specific Open Source Intelligence gathering or sending spearphishing emails) or untargeted by searching large repositories like GitHub for information formatted in a specific way. A practical example would include looking for published '.kube\textbackslash config' files, where authentication information and kube-apiserver addresses are saved to\footcite[][, section 'Define clusters, users, and contexts']{kubectlClusterAccess}. Gaining access through tokens in public logs has been demonstrated, too\footcite[][, section 'Results and notable findings']{ciKnew}.

%TODO mitigation!
%TODO dont forget
%default kubeconfig file location on user machine: $HOME/.kube/config <- contains certs + tokens for login, specifies which apiservers, ...
%get token from user: oc whoami --token
% call API with user token:	curl -X GET -H "Authorization: Bearer <token>" https://openshift.redhat.com:8443/oapi/v1 --insecure %
% login with user token:	oc login --token '<token>'
% check user rights: 

\newpage
\subsection{V16 - Leveraging bad infrastructure} \label{v16}
Even if the cluster itself is secured properly, an attacker may gain access through the underlying infrastructure if no security measures have been applied to it.
This includes the configuration of cloud infrastructure as well as on-premise configurations.
Servers may open insecure or unnecessary ports towards the public, as well as interfaces that allow someone any sort of control, i.e. allowing public access to the Docker remote API\footcite[][, section 'Publicly Accessible Docker Hosts']{dockerRemoteAccess}.
Internally, an attacker may access data belonging to other applications by leveraging side channel attacks like Spectre and Meltdown\footcite[][, section 'Which cloud providers are affected by Meltdown?']{spectreMeltdown}. \\
Measures against this include well known and documented security measures and best practices for traditional server infrastructure, including the full range of \gls{cis} benchmarks available\footcite[][, refer to the list presented]{cisBenchmarkList}.
Keeping the OS and programs of the underlying nodes minimal by only installing the necessary tools, functions and binaries may aid by reducing potential vulnerabilities on top of reducing the resource overhead.
Establishing a 'bastion host'\footcite[][, section 'What is a bastion host, and do I need one?']{bastionHostAws} as single point of remote entry to the cluster may be advisable if such functionality is required.
Measures can also be found in the \gls{owasp} \gls{csvs}\footcite[][, section 'Infrastructure']{csvsGithub}, \gls{cis} Docker Benchmark\footcite[][, chapters 1 through 3 and 5]{cisDocker}, the \gls{cis} Kubernetes Benchmark\footcite[][, chapters 'Worker Node Security Configuration' and 'Configuration Files']{cisK8s} and the NIST publication\footcite[][, chapters 3.5, 4.5 and 4.6]{nistK8s}.
Cloud configuration may be assessed and/or enforced with automated tools like ScoutSuite\footnote{https://github.com/nccgroup/ScoutSuite}, cloud-custodian\footnote{https://github.com/cloud-custodian/cloud-custodian} or environment-specific tools like azurite\footnote{https://github.com/mwrlabs/Azurite}.

\newpage
\subsection{V17 - Leveraging bad patch management} \label{v17}
An attacker may leverage publicly known vulnerabilities in software that is not up to date on any component used in the environment.
This may even include systems assumed to be responsible for by other parties. Even in \gls{paas} environments like \gls{aks}, servers have to be restarted by the cloud customer in order for some security updates to take effect. An example for this can be seen in an email sent to an Azure cloud account holder, a screenshot of which is provided in figure \ref{securityMailMS}. \\
Mitigating this is straightforward in theory - apply security updates, fixes and intermediary workarounds whenever they become available.
In practice this proves to be an ongoing real-world problem, as the WannaCry epidemic very publicly demonstrated\footcite[][, p. 2]{wannaCryPatching}.
Any and all unpatched components could pose a risk. Thus, responsibilities and guidelines should be defined for when and what to patch. Fallback plans accounting for vacation time and sick days should be implemented, too. The employees responsible for updating should set up or subscribe to their relevant vulnerability notification feeds, i.e. alerts for new vulnerabilities\footcite[][, first paragraph]{azureAlerts}.
Servers should follow conventional patch management processes, as these are similar to conventional system infrastructure. Kubernetes distributions should be kept up to date with updates provided by the \gls{k8s} distributor. Of note is the short time of guaranteed support by the \gls{k8s} reference implementation. The Kubernetes project maintains the most recent three minor releases with a new minor version planned approximately every three months\footcite[][, section 'Supported versions']{k8sSupport}. This would result in a cluster upgrade to be required every nine months in order to stay supported. Other distributions may have longer time periods of guaranteed support, i.e. \gls{ocp}\footcite[][, section 'OpenShift Container Platform v3']{ocpSupport}.
Applying updates to containers by updating container images should be done regularly. This includes both incrementing the version numbers of their base images to a version without currently known vulnerabilities as well as updating binaries directly downloaded during the build process. As an 'update' command run by the package manager during the build process works dynamically, security updates to those packages are included any time an image is built again. In consequence, images should be rebuilt periodically.
Using the image version tag 'latest' is not recommended, as this could automatically propagate bad images pushed to the image repository through to production environments\footcite[][, p. 40]{k8sBook}. Automated scanning may be implemented by open source tools like clair\footnote{https://github.com/coreos/clair}. Limiting the probability for new vulnerabilities by reducing the software installed as described in section \ref{v16} may help, too.

\chapter{Assessing the attack surface risk} \label{riskAssessTotal}
\setcounter{footnote}{0}
With the attack vectors identified, we introduce a customized risk estimation model for our purpose and explain the challenges of developing it. The model is then used to estimate the relative risk of each vector, specific to each solution.

\section{Defining procedures and approach}
Finding a framework to properly conduct a risk assessment has proven to be more difficult and time consuming than expected. The process and result are laid out in this section.

\subsection{Specification of environment factors} \label{envDefine}
In order to achieve a view on the risks more accurately resembling situations where a solution might be implemented, several assumptions are made:

\begin{itemize}

\item People in contact with the solution are familiar with conventional security principles and measures, but are new to the technologies used in the solutions within scope. They might even be new to container and cloud solutions in general. This includes users of the solution like developers and project managers as well as operators and administrators.

\item It is assumed that no special requirements like industry-specific compliance requirements have to be followed and the workloads processed within the solution have no exceptionally high security requirements. 

%TODO put this back in?
%\item Regarding the design and implementation of applications running on the solutions, it is assumed that conventional application security measures have been implemented, i.e. against the \gls{owasp} Top 10.\footcite[][, p. 4]{topten} The extent of those measures is assumed to be in accordance to moderate criticality of the data and service provided by the application.

\item Some risks increase or decrease drastically, depending on many specific configurations. Considering the high system complexity, ``getting it to work'' is hard enough for users and operators new to these technologies\footcite[][, starting at 3:05]{hackAndHarden}. While setting up and configuring a setup, the default configurations are left as-is whenever possible. Guidelines of specific implementations are followed, but whenever measures are presented as optional and not required, they will be skipped. Before recommending security measures, the setup will be modified just enough to become functional, without regards to the security implementations.

\item Multiple tenants like different customers, teams or projects are separated by \gls{k8s} namespaces or \gls{ocp} projects respectively, not by isolated clusters.

\end{itemize}

In addition to these assumptions, two specific implementations were selected and respective software versions were chosen. Additional solutions or software versions have not been assessed due to the exponential increase in workload to do so, but the process outlined in this thesis could be used to assess them, too.
The solutions were selected since they are both popular as well as there being specific interest in them by the company accompanying this thesis, HvS Consulting.
These include \gls{aks} as a public cloud solution and \gls{ocp} as an on-premise solution. As the latest stable version of \gls{ocp} during the beginning of this thesis was v3.11, this version was selected. It is based on \gls{okd} v3.11, which in turn is based on \gls{k8s} v1.11\footcite[][, refer to the second table below the headline 'Platform Components']{ocpK8sVersions}. \gls{aks} v1.13, directly correlating to \gls{k8s} v1.13 has already been available at this point\footnote{for more details, check figure \ref{aksVersionsMay}}, but v1.11 was chosen in order to achieve better comparability between the two solutions. This thesis will not look further into the upsides and downsides of faster availability in contrast to longer release and support cycles.

Whenever possible, all default settings were used to set up both solutions and get them functional. 
As a managed solution, the \gls{aks} settings are less distributed and detailed. An overview of the options chosen for the last \gls{aks} cluster setup of this thesis can be seen in figure \ref{aksConfig}.
Setting up the \gls{ocp} cluster was less straightforward and included steps with multiple options, but no defaults. The official setup guideline\footcite[][, sections 'Planning your installation' to 'Installing OpenShift']{ocpSetup} has been followed. A single master, single node setup was chosen. Multiple masters and (worker) nodes are recommended for production environments, but since this setup is purely used for assessment and demonstration, it is adequate to the task. Both nodes are virtual machines with sufficient resources in accordance to the documentation, running on \gls{rhel} 7.5. Best practices would recommend minimal OS setups like the \gls{rhel} Atomic Host offered by Red Hat, but this option has been chosen as such hosts are a common request within larger enterprises and as such faster and more easily available through preexisting processes in many corporate environments.

\newpage
\subsection{Deriving a risk estimation formula}
Generic methods of estimating risk may not lead to the most accurate results when assessing specialized systems like orchestrated container environments.
But since an initial search for risk assessment frameworks and methodologies specific to such environments proved unsuccessful, more generic frameworks were considered. 
The process laid out in the \gls{owasp} Risk Rating Methodology\footcite[][, sections 'Step 2' to 'Step 4' ]{riskRating} was an obvious choice, but discarded for the considerable effort needed to both map the generic ratings to indicators specific to our environment as well as estimating the sum of twelve to thirteen applicable factors per vector. Business impact factors would have been excluded since \gls{k8s} solutions are assessed in general, but for the exception of financial impact in case of cryptojacking where financial damage can be detached from the applications running on it.

Another methodology considered but decided against was the Common Vulnerability Scoring System in its most current version, v3. As specifically stated in its user guide, it is not intended to measure risk but instead measuring the severity of specific vulnerabilities\footcite[][, section '2.1. CVSS Measures Severity, not Risk']{cvssUserGuide}.

As an alternative, another methodology was proposed by the company accompanying this thesis, HvS Consulting. The generally accepted base formula of risk is the mathematical product of likelihood and impact, which forms the basis of this methodology. The impact is estimated directly, while the likelihood is calculated by summing up the estimation of several contributing factors. This is a simplified, but similar version of the \gls{owasp} Methodology\footcite[][, section 'Step 4: Determining the Severity of the Risk']{riskRating}. 

The original factors used to estimate a value for the likelihood were prevalence, awareness and exploitability. This methodology was customized in order to be more applicable, since prevalence would have been difficult to estimate and compare for the relatively new technologies. Instead of prevalence, the factors 'vantage point' and 'required access level' were added in order to explicitly consider both the possible origin of attack vectors as well as the privileges needed to leverage them. In contrast to other estimations they shall not influence the exploitability value, as the too much weight may then be put on these factors. The average value of these four factors lead to the resulting probability value. Customizing the factors is done to tailor towards our specific use case, a practice encouraged by the \gls{owasp} Risk Rating Methodology\footcite[][, section 'Step 6: Customizing the Risk Rating Model']{riskRating}.

As a simple comparison of the risk to each vector in relation to each other is sufficient to our use case, numerical values without unit instead of percentages or monetary amounts suffice. Compared to each other, they can be used to provide a prioritized list after the assessment.
The values for each respective factor were developed with the three scenarios derived in section \ref{scopeLimit} in mind. 
The initial idea was to map the numbers of one through three to reasonable indicators for each factor with a value of three indicating the most serious contribution to overall risk. During the process, this was expanded to the values zero through four for severe outliers.

The factor 'vantage point' increases in severity and value when it can be achieved more easily, as it would be easier to achieve it. It is valued at zero for situations that require more than a security baseline, i.e. physical access to the cluster nodes or hypervisors they may run on. A value of one is assigned for situations where commands need to be executed on the cluster nodes directly, as opposed to within the container. Command access to the containers is valued at two. Depending on the situation, access to the company network may be more difficult to achieve for an outside attacker than access to any single container, but from a cluster security perspective more people already have this sort of access. Therefore it is valued as a three, in contrast to the public internet accessible by anyone, which is an outlier in severity and assigned a value of four.

The '\gls{ral}' is incrementally increased when less privileges are needed, as this increases the factors contribution to the total risk.
Administrator access to the cloud environment or infrastructure underlying cluster nodes (i.e. equivalent access to the hypervisor in case the cluster nodes are VMs) is valued at zero, as this would again exceed baseline security requirements. Administrator access to the orchestrator or nodes is valued at one. User access to these systems is valued at a two where read and write privileges are needed and valued at three in cases where only read privileges are required. If no privileges or authentication is needed at all, a sever outlier value of four is assigned.

'Awareness' represents how easy it is for an attacker to become aware of this vector being feasible in general and in a specific system targeted for attack. As this is not applicable to negligent users, the value represents how easy it is to accidentally 'leverage' this vector instead. The assigned value rises with increased possibility for awareness, increasing the total risk estimation.
In order to be estimated to be unlikely and estimate at a value of one, custom-made tools would be needed to detect vulnerabilities. Accidental attacks which could happen during uncommon tasks would receive the same value, as both are custom to a system-specific environment. It is estimated to be possible and valued at two in cases where specific attacks could be done regardless of the specific environment but customization of generic tools is needed. If an accidental attack might happen during common tasks where tools or processes are not used the way they are intended, a value of two is also assigned.
The highest awareness value of three is assigned when attacks are both environment-agnostic as well as detectable by readily available tools or by simply using graphical user interfaces. It is valued at three in cases where proper usage of tools or processes during common tasks might accidentally lead to a security problem.

\newpage
The 'exploitability' factor differentiates between different levels of skill needed, increasing in value when less skill is required. In case of negligent users, it is simply valued the same as the awareness factor. It is valued at zero for situations that require more than a security baseline like unpublished and unknown exploitation of vulnerabilities. Synonymous to the definitions in the awareness factor, a difficult eploitability with a value of one would need custom tools for environment-specific exploitation, while an environment-agnostic exploit with require tool customization is valued as two. A value of three is again assigned when attacks are environment-agnostic and exploitable without tool customization or simple user interface interaction.

The impact value was roughly estimated by differentiating between intermediate steps and achieved damage as well as whether a single namespace or the whole cluster is affected. Intermediate steps were assigned a value of one, while outcomes confined to a single namespace and limited monetary damages are given a value of two. Compromises of the whole cluster and potentially unlimited monetary damages are valued at three for the most severe outcome rating.

\subsection{Resulting formula}
%TODO citation for risk product by pascal?!
The work elaborated on in the previous section leads to the following formula for estimating the total risk of the identified vectors, usable for a specific system setup at hand:

$${Total\ risk}= Max[\frac{ {vantage\ point}\ + {required\ access\ level}\ + {awareness}\ + {exploitability} }{4}*\ impact,\ 10]$$

%TODO formula misses rounding to full integer
This leads to a total risk of 0 through 10.5, which is rounded to full integers and capped at 10. In accordance to the \gls{owasp} Risk Rating Methodology\footcite[][, section 'Step 4: Determining the Severity of the Risk']{riskRating}, total risk values <= 3 are defined as low, <= 6 as medium and values above that are defined as high with the exception of 10, which is critical.
It should be noted that the worst case option of each vector should be taken in case of multiple possible scenarios, attacks and outcomes.

\newpage
\section{Estimating the solution specific risk} \label{riskEstimate}
%TODO move most vector estimate derivements to appendix?
%TODO get cell background colour working in latex tables? -> one shaded, one not?

Within this chapter, the estimated risk values of all vectors are presented for both the \gls{aks} and \gls{ocp} setups.
The details on how these values were determined are partially explained hereafter. 
The two vectors used in chapter \ref{riskMgmtTotal} are listed in full detail to serve as examples, details on the remaining vectors can be found in section \ref{riskAssessmentContd}.

\subsection{Overview of results}

The resulting risk estimation for both the \gls{ocp} and \gls{aks} example systems are illustrated in table \ref{estimateComparison}. The individual values these results are derived from can be seen in tables \ref{ocpRiskTable} and \ref{aksRiskTable}. 

\begin{table}[H]
\centering
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|l|c|c|}
\hline
{\ul{Vector ID}} & \multicolumn{1}{c|}{{\ul{Vector}}}                                                    & {\ul{OCP Risk}} & {\ul{AKS Risk}} \\ \hline
V01             & Reconnaissance through interface components                                            & \textbf{3}     & \textbf{3}     \\ \hline
V02             & Reading confidential information through interface components                          & \textbf{6}     & \textbf{7}     \\ \hline
V03             & Configuration manipulation through interface components                                & \textbf{7}     & \textbf{8}     \\ \hline
V04             & Compromise internal master components                                                  & \textbf{5}     & \textbf{6}     \\ \hline
V05             & Image poisoning and baiting                                                            & \textbf{7}     & \textbf{7}     \\ \hline
V06             & Configuration poisoning and baiting                                                    & \textbf{10}    & \textbf{10}    \\ \hline
V07             & Lateral movement through cluster                                                       & \textbf{7}     & \textbf{7}     \\ \hline
V08             & Container breakout                                                                     & \textbf{5}     & \textbf{7}     \\ \hline
V09             & Image cache compromise                                                                 & \textbf{3}     & \textbf{3}     \\ \hline
V10             & Container modification at runtime                                                      & \textbf{5}     & \textbf{5}     \\ \hline
V11             & Resource hoarding (sabotage)                                                           & \textbf{8}     & \textbf{6}     \\ \hline
V12             & Resource misuse (cryptojacking)                                                        & \textbf{5}     & \textbf{8}     \\ \hline
V13             & Adding rogue containers                                                                & \textbf{5}     & \textbf{6}     \\ \hline
V14             & Adding rogue nodes                                                                     & \textbf{6}     & \textbf{6}     \\ \hline
V15             & Leveraging bad user practice                                                           & \textbf{6}     & \textbf{6}     \\ \hline
V16             & Leveraging bad infrastructure                                                          & \textbf{9}     & \textbf{9}     \\ \hline
V17             & Leveraging bad patch management                                                        & \textbf{10}    & \textbf{10}    \\ \hline
\end{tabular}%
}
\caption{A comparison of the resulting risk for the \gls{ocp} and \gls{aks} environments\label{estimateComparison}}
\end{table}


\begin{landscape}
\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|l|cccc|cc|c|}
\hline
{\ul{Vector ID}} & \multicolumn{1}{c|}{{\ul{Vector}}}                                                      & \multicolumn{1}{c|}{{\ul{Vantage Point}}} & \multicolumn{1}{c|}{{\ul{RAL}}} & \multicolumn{1}{c|}{{\ul{Awareness}}} & {\ul{Exploitability}} & \multicolumn{1}{c|}{{\ul{Probability}}} & {\ul{Impact}} & {\ul{Resulting risk}} \\ \hline
V01             & Reconnaissance through interface components                                             & 3                                        & 3                              & 3                                        & 2                    & 2.75                                   & 1            & \textbf{3}           \\ \hline
V02             & Reading confidential information through interface components                                     & 3                                        & 3                              & 3                                        & 3                    & 3                                      & 2            & \textbf{6}           \\ \hline
V03             & Configuration manipulation through interface components                                & 3                                        & 1                              & 3                                        & 2                    & 2.25                                   & 3            & \textbf{7}           \\ \hline
V04             & Compromise internal master components                                                  & 3                                        & 1                              & 3                                        & 0                    & 1.75                                   & 3            & \textbf{5}           \\ \hline
V05             & Image poisoning and baiting                                                            & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 2            & \textbf{7}           \\ \hline
V06             & Configuration poisoning and baiting                                                    & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 3            & \textbf{10}          \\ \hline
V07             & Lateral movement through cluster                                                       & 2                                        & 2                              & 3                                        & 2                    & 2.25                                   & 3            & \textbf{7}           \\ \hline
V08             & Container breakout                                                                     & 2                                        & 2                              & 3                                        & 0                    & 1.75                                   & 3            & \textbf{5}           \\ \hline
V09             & Image cache compromise                                                                 & 1                                        & 1                              & 2                                        & 2                    & 1.5                                    & 2            & \textbf{3}           \\ \hline
V10             & Container modification at runtime                                                      & 2                                        & 2                              & 3                                        & 2                    & 2.25                                   & 2            & \textbf{5}           \\ \hline
V11             & Resource hoarding (sabotage)                                                           & 3                                        & 2                              & 3                                        & 2                    & 2.5                                    & 3            & \textbf{8}           \\ \hline
V12             & Resource misuse (cryptojacking)                                                        & 3                                        & 2                              & 3                                        & 2                    & 2.5                                    & 2            & \textbf{5}           \\ \hline
V13             & Adding rogue containers                                                                & 3                                        & 2                              & 3                                        & 2                    & 2.5                                    & 2            & \textbf{5}           \\ \hline
V14             & Adding rogue nodes                                                                     & 3                                        & 1                              & 2                                        & 2                    & 2                                      & 3            & \textbf{6}           \\ \hline
V15             & Leveraging bad user practice                                                           & 3                                        & 4                              & 2                                        & 2                    & 2.75                                   & 2            & \textbf{6}           \\ \hline
V16             & Leveraging bad infrastructure                                                          & 4                                        & 4                              & 2                                        & 2                    & 3                                      & 3            & \textbf{9}           \\ \hline
V17             & Leveraging bad patch management                                                        & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 3            & \textbf{10}          \\ \hline
\end{tabular}%
}
\caption{The risk estimation of all vectors for an \gls{ocp} 3.11 cluster\label{ocpRiskTable}}
\end{table}
%\captionof{table}{The risk estimation of all vectors for an \gls{ocp} 3.11 cluster\label{ocpRiskTable}}

\begin{table}[]
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|l|cccc|cc|c|}
\hline
{\ul{Vector ID}} & \multicolumn{1}{c|}{{\ul{Vector}}}                                                      & \multicolumn{1}{c|}{{\ul{Vantage Point}}} & \multicolumn{1}{c|}{{\ul{RAL}}} & \multicolumn{1}{c|}{{\ul{Awareness}}} & {\ul{Exploitability}} & \multicolumn{1}{c|}{{\ul{Probability}}} & {\ul{Impact}} & {\ul{Resulting risk}} \\ \hline
V01             & Reconnaissance through interface components                                             & 4                                        & 3                              & 3                                        & 2                    & 3                                      & 1            & \textbf{3}           \\ \hline
V02             & Reading confidential information through interface components                                     & 4                                        & 3                              & 3                                        & 3                    & 3.25                                   & 2            & \textbf{7}           \\ \hline
V03             & Configuration manipulation through interface components                                & 4                                        & 1                              & 3                                        & 2                    & 2.5                                    & 3            & \textbf{8}           \\ \hline
V04             & Compromise internal master components                                                  & 4                                        & 1                              & 3                                        & 0                    & 2                                      & 3            & \textbf{6}           \\ \hline
V05             & Image poisoning and baiting                                                            & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 2            & \textbf{7}           \\ \hline
V06             & Configuration poisoning and baiting                                                    & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 3            & \textbf{10}          \\ \hline
V07             & Lateral movement through cluster                                                       & 2                                        & 2                              & 3                                        & 2                    & 2.25                                   & 3            & \textbf{7}           \\ \hline
V08             & Container breakout                                                                     & 2                                        & 2                              & 3                                        & 2                    & 2.25                                   & 3            & \textbf{7}           \\ \hline
V09             & Image cache compromise                                                                 & 1                                        & 1                              & 2                                        & 2                    & 1.5                                    & 2            & \textbf{3}           \\ \hline
V10             & Container modification at runtime                                                      & 2                                        & 2                              & 3                                        & 2                    & 2.25                                   & 2            & \textbf{5}           \\ \hline
V11             & Resource hoarding (sabotage)                                                           & 4                                        & 2                              & 3                                        & 2                    & 2.75                                    & 2            & \textbf{6}           \\ \hline
V12             & Resource misuse (cryptojacking)                                                        & 4                                       & 2                              & 3                                        & 2                    & 2.75                                    & 3            & \textbf{8}           \\ \hline
V13             & Adding rogue containers                                                                & 4                                        & 2                              & 3                                        & 2                    & 2.75                                   & 2            & \textbf{6}           \\ \hline
V14             & Adding rogue nodes                                                                     & 4                                        & 1                              & 1                                        & 2                    & 2                                      & 3            & \textbf{6}           \\ \hline
V15             & Leveraging bad user practice                                                           & 4                                        & 4                              & 2                                        & 2                    & 3                                      & 2            & \textbf{6}           \\ \hline
V16             & Leveraging bad infrastructure                                                          & 4                                        & 4                              & 2                                        & 2                    & 3                                      & 3            & \textbf{9}           \\ \hline
V17             & Leveraging bad patch management                                                        & 4                                        & 4                              & 3                                        & 2                    & 3.25                                   & 3            & \textbf{10}          \\ \hline
\end{tabular}%
}
\caption{The risk estimation of all vectors for an \gls{aks} 3.11 cluster\label{aksRiskTable}}
\end{table}
%\captionof{table}{The risk estimation of all vectors for an \gls{aks} 3.11 cluster\label{aksRiskTable}}
\end{landscape}

\subsection{V07 - Lateral movement through cluster}

The \gls{ocp} setup will be elaborated on first. Once an attacker can execute commands within a container (Vantage Point: 2) and is able to send network requests (RAL: 2), they can scan the network for other containers, hosts, services, apis or similar interfaces for further access. By default, all containers in all projects (except master \& infra components) are put in the same subnet, allowing everyone to communicate with anyone else, including application components belonging to other tenants. These components may rely on the restriction of network access to them instead of authorizing individual requests (Impact: 3).
Network scanning tools and accompanying tutorials are readily available (Awareness: 3), but their results depend on the deployed applications. Therefore some technical expertise is needed to leverage the network access (Exploitability: 2). 
With a total risk value of 7, it is classified as a high risk. \\
The circumstances in the \gls{aks} setup are identical to \gls{ocp}, resulting in the same risk values.

\subsection{V08 - Container breakout}

In the \gls{ocp} setup, a deployed container poses the risk of allowing access to the node it is running on, thus allowing an attacker with the ability to admit new containers (RAL: 2) to break out of the container (Vantage Point: 2) and perform actions on the node.
This poses a considerable threat, since any container may run on any node by default, allowing an attacker full access to any containers running on the node he controls, which will  especially over time  have a great chance to include containers belonging to other projects (Impact: 3).
The \gls{ocp} default settings limit the possibility of this dramatically, as both privileged containers and those executed as root user are prevented from being run. Network and file system access as well as kernel capabilities are limited, too. In order to affect the host, software vulnerabilities would be needed (Exploitability: 0).
The risk lies more in organizations relaxing the default configuration in favor of easy usability, since a majority of container images straight from docker hub require UID 0 and thus a root user. The easiest way to stop those problems this is to permit the default service account within a project access to the privileged \gls{scc} permissions. This would significantly increase the risk of a container breakout, but is not considered here as the default configuration is assessed.
This is probably the most-talked about attack vector regarding containers (Awareness: 3), but techniques are not obviously documented and breakout methods would have to be customized to the restrictions applied within a cluster.
With a total risk value of 5, it is classified as a medium risk. \\
The \gls{aks} setup differs from these circumstances by having no restrictions to admitted pods in place. Thus, this vector is more easily exploitable (Exploitability: 2).
The total risk value is increased from 5 to 7 by this, leading to a high risk.

\chapter{Managing the attack surface risk} \label{riskMgmtTotal}
\setcounter{footnote}{0}
With this chapter, the \gls{owasp} Risk Rating Methodology\footcite{riskRating} is continued. As completing the risk management process would exceed the scope of this thesis, the full process will be described and the risk management steps will be demonstrated through two exemplary vectors.

\section{Defining procedures and approach} \label{riskMgmtApproach}
Before managing the risk, the risk appetite\footcite[][, first paragraph]{riskAppetite} should be decided on, defining what residual risk levels are acceptable.
As the goal is to provide a security baseline, reducing the risk to below 'critical' and 'high' will be taken as a goal.
This defines the work ahead, as any risk above this threshold is intended to either be accepted (i.e. in cases where the cost of implementing security measures exceeds the potential damage costs) or reduced to an acceptable level.
The set of vectors above the risk appetite are commonly ordered in descending order of their total risk value.
Typically, one would start with the vector currently presenting the highest overall risk. 
After selecting sensible security measures, the residual risk of all vectors should be reassessed, as some measures may influence multiple vectors. 
The new risk values lead to a new order of vectors by descending risk, of which new highest vector will be selected. New security measures should again be selected and this cycle continued until the remaining risk is acceptable.

Which measures to select may depend on specific setups, use cases and available resources, as these would considerably influence factors like the implementation cost of each measure. Some measures will be the best choice in almost all circumstances. These would be considered best practices.

As the process is not fully completed within this thesis, the vectors chosen to demonstrate the process were not the ones with the highest overall risk.
Two other vectors were chosen instead, since these were more representative of the environments within scope and concise enough to properly present the process. Examples like securing the underlying physical servers or VMs are suboptimal for representing the process of securing a solution based on orchestrated containers.

A specific attack for each vector has been conducted and will be examined for demonstration. Security measures will be chosen and implemented, after which the successful prevention of the attack will be shown.
The remaining risk will be reassessed for all vectors, as some measures may influence others.

\section{Managing the risk of V07 - Lateral movement through cluster} \label{v07ManageTotal}
This section will demonstrate the possibility of attackers to leverage network access to other containers in a cluster, across namespace/project boundaries.

Both the \gls{aks} and \gls{ocp} clusters set up as specified in section \ref{envDefine} have been vulnerable to attacks leveraging the attack vector specified in section \ref{v07}. This is possible with the default settings for both clusters, as will be demonstrated. Security measures will be implemented and their effectiveness demonstrated. The risk management process will be demonstrated on the basis of these circumstances.

\subsection{Demonstrating the successful attack without security measures}
The \gls{ocp} cluster contains several projects, two of which are relevant to the situation at hand. 
The 'sock-shop' project contains the Sock Shop, a microservice demo application that is open source and implements an online store for the purchase of various socks\footcite[][, first paragraph of 'README.md']{sockShop}.
The 'testuser' project is used to simulate an attacker-controlled container admitted to another project.

The project namesand  services admitted by the sock shop application are seen in listing \ref{lst:lateral-ocp-prep}. One of these services is called user-db, reachable through the cluster-internal IP 172.30.2.17 and listening to port 27017. This port is commonly used by the database solution MongoDB\footcite[][, first table row]{mongoPort}. The listing also shows the configuration file for the attacking container placed within a \gls{k8s} pod. It contains basic networking tools and runs a wait-loop to both simulate a running container as well as keep the pod from terminating. The listing also shows the privileges needed to admit this pod into the cluster, which is permitted even by unprivileged security context constraints\footcite[][, refer to table of section 'Listing Security Context Constraints']{sccDefaults}. After the pod is admitted and created through the oc apply command, a remote shell is opened through oc rsh in order to execute commands from within the simulated attacker context.

Listing \ref{lst:lateral-ocp-exploit} shows the commands and output used to steal (fake) login, address and payment information from within the sock shop.
The nmap tool is already installed and used to scan for MongoDB databases. This would take a considerable amount of time to do for the whole IP range of the cluster, which is why we resctricted it to the service IP we know to route to the user-db service. The output not only confirms that we can reach it from another namespace, but also shows three databases on it - local, admin and users.
For usability purposes during the attack, the MongoDB shell is directly downloaded and installed during container runtime and used to connect to the database found. Since no access control is enabled, all databases can be enumerated and login, user as well as credit card data can be printed to the shell output.

The same attack was successfully conducted on the \gls{aks} setup, only the commands used differ slightly. Details can be found in listings \ref{lst:lateral-aks-prep} and \ref{lst:lateral-aks-exploit}.

\subsection{Selecting and implementing security measures}

A number of security measures could be used to mitigate this problem.
The mongodb database could have restricted access and only be available with a password. 
As a platform provider, application security measures like this may be unfavorable or unenforceable, so other measures would be preferrable.

Section \ref{v07} outlines network isolation and mTLS authentication with Istio as possible solutions. As the simulated attacking container has been legitimately admitted, this would not prevent an attack. As such, network isolation will be implemented in order to defend against this.
In order to provide the most limiting and save isolation without impacting functionality, each any container would have to be assessed for their communication needs and restricted to only these. In addition, this would have to be reassessed every time a new type of container/pod is introduced to the cluster or application code changes, as the communication need may change. In order to avoid this considerable effort, a compromise between usability and security can be made. Isolating each \gls{ocp} project and \gls{aks} namespace by default, but allowing any network communication within the project or namespace would limit lateral movement to these confinements while still allowing for rapid changes to the applications and their containers within a project or namespace. 

The easiest way to achieve this on the \gls{ocp} cluster is to use the ovs-multitenant network plugin, which implements this isolation by default for any existing as well as newly created project\footcite[][, section 'Overview']{ocpNetworkPlugins}. The \gls{aks} cluster would need a default network policy\footcite[][, section 'Default Policies']{egressNetPol} to isolate namespaces, examples of which are publicly available\footcite[][, section 'Example']{netPolExample}.

An \gls{aks}-specific challenge to note here is the current effort for mitigation not made clear by the Microsoft documentation. The network policy usage tutorial clearly states that "[t]he network policy feature can only be enabled when the cluster is created. You can't enable network policy on an existing AKS cluster"\footcite[][, section 'Frequently asked questions']{aksNetPolUse}. This information is currently not given in the official \gls{aks} cluster deployment tutorial\footcite{aksSetup}. When a cluster is set up, it defaults to the Basic option for network configuration at the time of this writing. This would require a full cluster rebuild and application migration in order to migrate to using network policies, as was the case during the practical part of this thesis.
Even with this increased effort, using network policies is still recommended.

The official documentation for migrating to the ovs-multitenant plugin\footcite{networkPluginSwitch} was followed to implement the security measures for the \gls{ocp} cluster. A new \gls{aks} cluster was built with the settings detailed in figure \ref{aksConfig} and all applications as well as the simulated attacker have been reconfigured and redeployed. A network policy denying all incoming traffic from other namespaces was applied to the sock shop namespace as detailed in listing \ref{lst:lateral-aks-mitigate}.

\subsection{Demonstration with implemented security measures}

After isolating network communication to each \gls{ocp} project and \gls{aks} namespace respectively, the simulated attacking container will not be able to access the sock shop database anymore. As seen  in listings \ref{lst:lateral-ocp-mitigate} and \ref{lst:lateral-aks-mitigate}, both connection requests terminate with an 'exception: connect failed'.

\subsection{Risk reassessment}

Isolating each application or team to its own network limits the reach to other containers within this application. As other projects or namespaces cannot be reached anymore, an attacker won't be able to compromise them. This reduces the impact from a potential compromise of multiple applications (Impact: 3) to a single one (Impact: 2).
In keeping the remaining values and formula, this reduces the total risk value for both the \gls{aks} and \gls{ocp} cluster from 7 to 5, resulting in a medium risk estimation instead of the high risk it was estimated at before implementing the security measures. Thus, the reduced risk is acceptable in accordance with the goal set in section \ref{riskMgmtApproach}.

\section{Managing the risk of V08 - Container breakout}

This section will demonstrate the possibility of attackers to break out of the container environment and into the host system.

Both the \gls{aks} and \gls{ocp} clusters set up as specified in section \ref{envDefine} have been vulnerable to attacks leveraging the attack vector specified in section \ref{v08}. This is possible with the default settings for the \gls{aks} cluster, while some \gls{ocp} default settings had to be changed in order to achieve this.
The 'privileged' \gls{scc} is added to the default user of the project from which the attack is conducted.
The attacks on both clusters as well as the configuration changes made will be demonstrated. Security measures will be implemented and their effectiveness illustrated. The risk management process will be demonstrated on the basis of these circumstances.
%TODO explain which settings have to be changed on ocp

\subsection{Demonstrating the successful attack without security measures} \label{v08attack}
Listing \ref{lst:breakout-aks-exploit} shows the commands used and output returned in an attack demonstration on the \gls{aks} cluster.
The pod configuration file printed to the command line contains a single, privileged container running multiple commands on admission.
A sleep loop is executed at the end in order to keep the cluster from continuously restarting the pod with its otherwise terminating container.
The container simply mounts the root filepath of its host, the underlying worker node, in the container file system as '/mnt/rootnode'. 
The commands executed are all permitted to read and write to the specified file path, as the User ID of the executing user is 0, the root user. Since it is a privileged container, this is not only the case for the container environment, but also the mounted host file system.
The \gls{k8s} pod admission is started and after a short amount of time, its logs are printed to the console. 
These logs contain both the {\slash}etc{\slash}passwd and {\slash}etc{\slash}shadow file contents as well as the presumed node root directory with a file named ALL{\_}YOUR{\_}NODES{\_}ARE{\_}BELONG{\_}TO{\_}US written to it.
This root file system is checked by directly accessing the host file system of the node. Although it is unusual to do this on dedicated VMs automatically created specifically for \gls{k8s} clusters, \gls{aks} offers specific functionality to do this\footcite{aksNodeSsh}. Listing \ref{lst:breakout-aks-nodeOutput} shows that the file was indeed written to the node.
The output seen in listing \ref{lst:breakout-aks-exploit} is partially edited in order to shorten the document as well as to not disclose any password hashes.

The same attack was successfully conducted on the \gls{ocp} setup, only the commands used differ slightly. Details can be found in listings \ref{lst:breakout-ocp-exploit} and \ref{lst:breakout-ocp-nodeOutput}.

\subsection{Selecting and implementing security measures} \label{measures2}
A number of security measures could be used to mitigate this problem.
Sandboxing containers may help, but the resource overhead comes at a non-significant cost, which is why a focus is placed on restricting container privileges first.
The recommended way to do this is through \gls{scc} restrictions in \gls{ocp} clusters and pod security policies in \gls{aks} clusters. These allow the restriction of multiple privileges in one place. Additionally, they can be applied to any new containers before admission when they are configured as applicable by default.
Even though this feature is an \gls{aks} preview feature and not recommended for production use by Microsoft\footcite[][, second paragraph with the headline 'important']{aksPodSecPol}, implementing these restrictions through other means would require far more effort. Due to this, it is still recommended to use this feature.

The goal is to limit container privileges in a way that reduces the risk of a container breakout to an acceptible level while minimizing the impact on platform usability.
A number of settings can be changed, which is why this thesis will derive general recommendations here. These may need to be tailored to a specific use case when exceptional circumstances arise, i.e. mounting of host files is both widespread and needed.

In order to successfully attack the underlying host in the attack demonstrated above, the container has to be run as both privileged and under the root user within the container itself. Additionally, host file mounts have to be permitted. If any of these three are prohibited, this specific attack will not be successful. However, implementing a single restriction may not be taken as a guaranteed protection. Other attacks may still work, as even a non-root user may be able to read confidential information on the host file system. Following the security principle of defense in depth, multiple controls should be applied.

\newpage
A common recommendation is to restrict containers from running as root. This would restrict a malicious user from numerous attacks, as they lack the required permissions to i.e. write files or execute commands. At the same time, this would prevent many container images to work in their default settings, as both the provided images on docker hub and the executed programs generally assume that they are started with root permissions. It is possible that the permissions required are undocumented or even non-customizable without code changes. This would either require a significant amount of debugging and customization or exceptions from this restriction. In order to avoid this additional workload and usability decline, other alternatives will be recommended.

Unprivileged containers could run as a root user with root privileges within the container, but none outside it. This leaves programs inside the container with any permissions they may need to function, while granting none outside the container environment. File mounts are not commonly required in container environments as relying on container-external files would go against the very philosophy of such environments. Due to this, they will be permitted in order to reduce the possibility of access to the node. As some container escapes may require the SYS{\_}ADMIN capability\footcite[][, section 'Requirements to use this technique']{trailOfBitsEscape}, which is typically not required by applications, it too can be prohibited. Users and containers should also not be allowed to elevate privileges by themselves. Other successful breakout attacks may require outdated software or cluster components, i.e. by leveraging old versions of the low-level container runtime runc\footcite[][, section 'What Is The Vulnerability?']{runcVuln}. This would be mitigated by the security measures against V17 and are not taken into account here.

The \gls{ocp} configuration offers multiple preconfigured \gls{scc} settings. In order to suit the requirements derived above, the 'anyuid' \gls{scc} is recommended for \gls{ocp} clusters.
In order to apply the restrictions above to \gls{aks} clusters a pod security policy has to be defined, as at the time of this writing none are present in the default configuration. The official \gls{k8s} documentation\footcite[][, section 'Example Policies']{securityPolicy} offers the information and examples needed to achieve this.
%TODO write default settings, put in appendix, \ref here!

Listing \ref{lst:breakout-ocp-mitigate} shows that the admission of the container used to conduct the \gls{ocp} cluster breakout is only permitted by the 'privileged' \gls{scc}. Removing it from the service account that is allowed to use it stops it and thus keeps the pod and its container from being admitted to the cluster.
Listing \ref{lst:breakout-aks-mitigate} shows the commands used and output returned while implementing the security measures on the \gls{aks} cluster, following the official guideline\footcite[][, section 'Enable pod security policy on an AKS cluster']{aksPodSecPol}. The returned output is partially edited in order to shorten the document as well as to not disclose any confidential information.

\newpage
\subsection{Demonstration with implemented security measures}

Limiting the privileges of pods and the containers within prevents them from successfully breaking out of the container isolation environment.
The container used to conduct the attack in section \ref{v08attack} requires these privileges and is therefore not allowed to be submitted to the cluster. This can be seen in listing \ref{lst:breakout-ocp-mitigate} for the \gls{ocp} cluster and in listing \ref{lst:breakout-aks-mitigate} for thhe \gls{aks} cluster.

\subsection{Risk reassessment revisited} \label{reassess2}

The \gls{ocp} risk for V08 is already estimated to be a medium risk, so no security measures would have to be implemented for it. This is due to the assumption of default settings, which deny the privileges needed for the demonstrated attack. Since this also significantly decreases the usability, as discussed in section \ref{measures2}, it is not recommended to leave it in its default configuration.
Granting all projects permissions to use the 'anyuid' \gls{scc} allows containers to run as root users. This increases the estimated risk, since more privileges are granted and can potentially be leveraged. No specific attacks leveraging these additional privileges were found during the research for this thesis. The increased risk is still accounted for by increasing the exploitability factor from theoretical to difficult (Exploitability: 1). This increases the total risk from 5 to 6, which is still an acceptable medium risk. Another positive effect of this measure is the decreased possibility of granting unneeded additional privileges in situations where i.e. time constraints may lead to administrators simply granting a project the 'privileged' \gls{scc}. This could otherwise lead to increased risk later on, but such a 'risk of potential future risk increase' is unaccounted for in our risk model.

The \gls{aks} risk decreases by applying the pod security policy to all namespaces in a cluster, also accounted for by estimating the exploitability factor as difficult (Exploitability: 1). This decrease from a former average exploitability estimation decreases the resulting total risk from 7 to 6, now a medium risk.
Thus, the reduced risk is acceptable in accordance with the goal set in section \ref{riskMgmtApproach}.

No other vectors are influenced by these measures. If root users within the container were prohibited, the exploitability factor of V10 could have been re-estimated as difficult. Since this is not the case, an attacker able to execute commands within a container can still to so with root privileges. Since V10 is estimated to be a medium risk for both clusters, this is acceptable.

\chapter{Conclusion}
The emerging generic security risks and pointers to security measures were detailed in chapter \ref{deriveRisks}. A process to mitigate these risks has been introduced in chapter \ref{riskMgmtTotal}. 
This chapter aims to provide answers to the remaining question posed in section \ref{goal} by comparing the \gls{aks} and \gls{ocp} solutions based on the assessment of chapter \ref{riskAssessTotal}, as well as provide a closing summary.

\section{Comparing on-premise and public cloud}

Since both the gravity of each risk and the comparison of on-premise and public cloud solutions would depend on a multitude of factors, the \gls{ocp} and \gls{aks} setup will be compared specifically. They respectively represent on-premise and public cloud solutions within the scope of this thesis. It should be noted that this comparison should not be generalized to hold true for all respective solutions.

The comparison is based on the values derived from the default settings shown in table \ref{estimateComparison} and therefore ignores factors like the difficulty of implementing certain security measures. This would have required a full selection of security measures and research into how to conduct them for each platform, which is out of scope for this thesis.


The overall risk of \gls{aks} is slightly higher, both due to being accessible from the public internet as well as more lenient default limitations. The former is understandable due to the nature of cloud solutions. The latter may be a result of usability being a higher priority. \\
The \gls{ocp} default settings stand in contrast to this, i.e. by preventing many popular images from being run since they require root privileges within the container environment. This alludes to a mindset of security by default, which reduces the existing risk. Nevertheless, other factors as i.e. outdated servers or negligent employees result in risks which can not be mitigated by the solution itself. Additionally, very limited default settings may lead to configuration changes in order to increase productivity. These changes, especially when overcompensated, could increase risks in such significant ways that a more sensible and less restricting default configuration would have been better off.
%TODO say something on on-demand resources, sabotage via DOS vs. cryptojacking!

% FOLLOWING SECTION SCRAPPED FOR THESIS! left as comment for reference
%\subsection{Multi-tenant isolation}
%Comments on multi-tenant usage
%keep this in? not a well-defined question in the beginning
%namespace/project isolation vs. cluster isolation. refer to separate-tenants-by-cluster measure in vector identification section. Is possible, but more complex and tedious ATM. refer to growing projects for cluster federation and clusters-as-cattle (instead of container-as-cattle and cluster-as-pet)
%-> may be better in future, only do today for super-high-security apps in their own cluster. costs more resources, at which point one may simply run the stuff on isolated and dedicated servers anyway (except when needed for workflow, high availability or mircoservice arch offsets complexity needed)?

\newpage
\section{Closing remarks}

Although the initial goal including a comprehensive list of security measures and best practices had to be changed, I am content with the result. The amount of work needed for both the derivation of security vectors and tailoring of the risk model to meet the requirements took far more work than anticipated. This is in part due to the limits of existing research as well as the significant difference to other platforms and architectures. The initial goal of comparing the risk of on-premise and public cloud had to be changed due to being highly dependent on solution-specific details. This may get easier in the future as robust solutions form and are adopten in other solutions.

The risk estimation formula could still be improved upon, in example by incorporating the expenditure needed for mitigation. For most use cases in the industry, this effort may instead be better used to actually reduce the risks, even when some risks are slightly over- or underestimated. 
A lot of improvements to the available security measures in \gls{k8s} solutions have been made in the last few years or are still ongoing, i.e. pod security policies reaching preview status in \gls{aks}. New features like the \gls{k8s} runtime class\footcite[][, section 'Motivation']{runtimeClass} are nearing a stable state and will make sandboxing of specific pods easier. Several solutions for rootless container builds\footcite[][, slides 10 to 11]{rootlessBuilds} are also actively being worked on for multiple solutions at the time of this writing. 

I personally hope for further collaboration, solidifying security measures and best practices in this fast evolving area.
Likewise, I hope that this thesis helps the inclined reader to accelerate their task to secure orchestrated container environments, so the considerable amount of time invested was not spent in vain.
